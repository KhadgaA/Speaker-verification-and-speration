{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxceleb = torchaudio.datasets.VoxCeleb1Verification(r'/mnt/d/programming/datasets/VoxCeleb', download=True,meta_url=\"/mnt/d/programming/datasets/VoxCeleb/list_test_hard2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform= torchaudio.transforms.Resample(orig_freq=16000, new_freq=8000)\n",
    "def collate_fn(batch):\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "test_loader = torch.utils.data.DataLoader(voxceleb, batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 0.0904,  0.0674, -0.0121,  ...,  0.1079,  0.1278,  0.1056]]]),\n",
       " tensor([[[-0.0027, -0.0041, -0.0081,  ...,  0.0007,  0.0007,  0.0006]]]),\n",
       " tensor([16000]),\n",
       " tensor([0]),\n",
       " ('id10054-aBpmA6-g2uw-00005',),\n",
       " ('id10677-s1sqH8pCwas-00009',)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python verification_wvlm.py --model_name wavlm_base_plus --wav1 trial_wavs/hn8GyCJIfLM_0000012.wav --wav2 trial_wavs/HXUqYaOwrxA_0000015.wav --checkpoint C:\\Users\\KHADGA JYOTH ALLI\\Desktop\\programming\\Class Work\\IITJ\\Speech Understanding\\Assignment 2\\model_checkpoints\\wavlm_base_plus_nofinetune.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav1_dir=r\"/mnt/c/Users/KHADGA JYOTH ALLI/Desktop/programming/Class Work/IITJ/Speech Understanding/Assignment 2/trial_wavs/hn8GyCJIfLM_0000012.wav\"\n",
    "wav2_dir=r\"/mnt/c/Users/KHADGA JYOTH ALLI/Desktop/programming/Class Work/IITJ/Speech Understanding/Assignment 2/trial_wavs/xTOk1Jz-F_g_0000015.wav\"\n",
    "            \n",
    "# wav1, wav2, label = batch\n",
    "wav1, sr1 = torchaudio.load(wav1_dir)\n",
    "wav2,sr2 = torchaudio.load(wav2_dir)\n",
    "resample1 = torchaudio.transforms.Resample(orig_freq=int(sr1), new_freq=16000)\n",
    "resample2 = torchaudio.transforms.Resample(orig_freq=int(sr2), new_freq=16000)\n",
    "wav1 = resample1(wav1)\n",
    "wav2 = resample2(wav2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 78721])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav1.squeeze_(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 142721])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav2.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
